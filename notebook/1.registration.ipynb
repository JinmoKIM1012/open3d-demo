{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d3eb8a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates various **pair-wise point cloud registration** methods implemented in Open3D.\n",
    "\n",
    "\n",
    "The registration methods can be roughly grouped into two categories.\n",
    "\n",
    "1. Global Registration\n",
    "\n",
    "The **global registration** is a family of registration methods that aims to recover the relative 3D rigid transformation between two possibily overlapping point clouds.  \n",
    "They estimate the rough alignment of input point clouds without requiring the initial alignment information.  \n",
    "There are two available global registration methods implemented in Open3D: **RANSAC** and **FGR**.  \n",
    "\n",
    "2. Local Registration\n",
    "\n",
    "Unlike global registration methods, the **local registration methods** process roughly aligned point clouds and outputs refined transformation that tightly align two point clouds.  \n",
    "Iterative Closest Points (ICP) is the one of the most representative local registration methods.  \n",
    "In Open3D, two variants of ICP is provided: 1. point-to-point ICP and 2. point-to-plane ICP.  \n",
    "\n",
    "\n",
    "In this tutorial, we demonstrate both global registration (RANSAC, FGR) and local registration (ICP) on real-world indoor RGB-D datasets using Open3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9130da-7d47-4b72-ad9c-29855e307a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2206c6",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Dataset preparation\n",
    "\n",
    "The first step in this tutorial is to download datasets and preprocess them.  \n",
    "In Open3D, there is a helper function to download various demo datasets for various tasks.  \n",
    "\n",
    "For global registration methods, we need to extract local geometric features from point cloud data to perform feature matching.\n",
    "In this tutorial, we compute FPFH feature for each point.  \n",
    "The FPFH feature is a 33-dimensional vector that describes the local geometric property of a point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pcd(pcd, voxel_size):\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 2.0, max_nn=30)\n",
    "    )\n",
    "    feature = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size * 5.0, max_nn=100),\n",
    "    )\n",
    "    return pcd_down, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fd064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(voxel_size):\n",
    "    pcds = o3d.data.DemoICPPointClouds()\n",
    "    src_pcd = o3d.io.read_point_cloud(pcds.paths[0])\n",
    "    tgt_pcd = o3d.io.read_point_cloud(pcds.paths[1])\n",
    "\n",
    "    src_down, src_feature = preprocess_pcd(src_pcd, voxel_size)\n",
    "    tgt_down, tgt_feature = preprocess_pcd(tgt_pcd, voxel_size)\n",
    "    return src_down, src_feature, tgt_down, tgt_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc678e",
   "metadata": {},
   "source": [
    "The below function visualize registration results using Open3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85019e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_registration_results(src, tgt, trans, title=None):\n",
    "    src_copy = copy.deepcopy(src)\n",
    "    tgt_copy = copy.deepcopy(tgt)\n",
    "\n",
    "    src_copy.paint_uniform_color([1, 0.706, 0])\n",
    "    tgt_copy.paint_uniform_color([0, 0.651, 0.929])\n",
    "\n",
    "    src_copy.transform(trans)\n",
    "    o3d.visualization.draw_geometries(\n",
    "        [src_copy, tgt_copy],\n",
    "        window_name=title,\n",
    "        zoom=0.8,\n",
    "        front=[0.6452, -0.3036, -0.7011],\n",
    "        lookat=[1.9892, 2.0208, 1.8945],\n",
    "        up=[-0.2779, -0.9482, 0.1556],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d54133",
   "metadata": {},
   "source": [
    "This code below visualizes the two point clouds with their initial aligment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528febe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOXEL_SIZE = 0.05  # 2cm\n",
    "src_pcd, src_feature, tgt_pcd, tgt_feature = prepare_dataset(VOXEL_SIZE)\n",
    "draw_registration_results(src_pcd, tgt_pcd, np.eye(4), title=\"before registration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f454b",
   "metadata": {},
   "source": [
    "## 2. RANSAC\n",
    "\n",
    "First, we use RANSAC for global registration. \n",
    "RANSAC takes two point clouds and corresponding FPFH features and estimate the rigid transformation parameters by repeating multiple iterations of *hypothesis-then-verify* loop.\n",
    "In Open3D, the function ```registration_ransac_based_on_feature_matching``` is implemented in the ```o3d.pipelines.registration``` namespace.\n",
    "There are various arguments we need to set up. Please check the Open3D's documentation for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85697fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_registration_by_ransac(\n",
    "    src_pcd, src_feature, tgt_pcd, tgt_feature, voxel_size\n",
    "):\n",
    "    ts = time.time()\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        src_pcd,\n",
    "        tgt_pcd,\n",
    "        src_feature,\n",
    "        tgt_feature,\n",
    "        mutual_filter=True,\n",
    "        max_correspondence_distance=voxel_size * 1.5,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPoint(\n",
    "            False\n",
    "        ),\n",
    "        ransac_n=3,\n",
    "        checkers=[\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                voxel_size * 1.5\n",
    "            ),\n",
    "        ],\n",
    "        criteria=o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999),\n",
    "    )\n",
    "    print(f\"[RANSAC] takes {time.time() - ts:.3f} (s)\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c85f8a",
   "metadata": {},
   "source": [
    "The below code visualizes the results of RANSAC. As can be seen in the visualization, RANSAC successfully align input point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ransac = global_registration_by_ransac(\n",
    "    src_pcd, src_feature, tgt_pcd, tgt_feature, VOXEL_SIZE\n",
    ")\n",
    "draw_registration_results(\n",
    "    src_pcd, tgt_pcd, result_ransac.transformation, \"after global registration [RANSAC]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd4892e",
   "metadata": {},
   "source": [
    "## 3. FGR\n",
    "\n",
    "Although RANSAC has been chosen as the de facto standard global registration method for long time, it may takes a long time due to the countless proposals and evaluations.\n",
    "FGR proposes a faster approach by eliminating repetitive proposal and evaluations and quickly optimizes the line process weights of few correspondences.\n",
    "\n",
    "The below function run the FGR implmented in ```registration_fgr_based_on_feature_matching``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac9b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_registration_by_fgr(src_pcd, src_feature, tgt_pcd, tgt_feature, voxel_size):\n",
    "    ts = time.time()\n",
    "    result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching(\n",
    "        src_pcd,\n",
    "        tgt_pcd,\n",
    "        src_feature,\n",
    "        tgt_feature,\n",
    "        o3d.pipelines.registration.FastGlobalRegistrationOption(\n",
    "            maximum_correspondence_distance=voxel_size * 0.5\n",
    "        ),\n",
    "    )\n",
    "    print(f\"[FGR] takes {time.time() - ts:.3f} (s)\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fgr = global_registration_by_fgr(\n",
    "    src_pcd, src_feature, tgt_pcd, tgt_feature, VOXEL_SIZE\n",
    ")\n",
    "draw_registration_results(\n",
    "    src_pcd, tgt_pcd, result_fgr.transformation, \"after global registration [FGR]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbc3f5",
   "metadata": {},
   "source": [
    "## 4. Local Registration (ICP)\n",
    "\n",
    "Finally,  we demonstrate ICP, a local registration method that is capable of refining rough intial aligment from global registration methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2cab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_registration_by_icp(\n",
    "    src_pcd, src_feature, tgt_pcd, tgt_feature, trans_init, voxel_size\n",
    "):\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        src_pcd,\n",
    "        tgt_pcd,\n",
    "        voxel_size * 0.4,\n",
    "        init=trans_init,\n",
    "        estimation_method=o3d.pipelines.registration.TransformationEstimationPointToPlane(),\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ce90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_local = local_registration_by_icp(\n",
    "    src_pcd, src_feature, tgt_pcd, tgt_feature, result_ransac.transformation, VOXEL_SIZE\n",
    ")\n",
    "draw_registration_results(\n",
    "    src_pcd, tgt_pcd, result_local.transformation, \"after local registration\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b074b",
   "metadata": {},
   "source": [
    "## 5. Multi-way Registration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a15e6",
   "metadata": {},
   "source": [
    "This code below prepare the dataset for multi-way registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40988f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_multiway_dataset(voxel_size):\n",
    "    results = []\n",
    "    dataset = o3d.data.DemoICPPointClouds()\n",
    "    for p in dataset.paths:\n",
    "        pcd = o3d.io.read_point_cloud(p)\n",
    "        pcd_down = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "        results.append(pcd_down)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47284f78",
   "metadata": {},
   "source": [
    "First we setup the hyperpatemeters including voxel size and two distance thresholds for hierarchical ICP.  \n",
    "\n",
    "As can be seen in the visualization, the point clouds are provided without alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca264c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOXEL_SIZE = 0.02\n",
    "max_correspondence_distance_coarse = VOXEL_SIZE * 15\n",
    "max_correspondence_distance_fine = VOXEL_SIZE * 1.5\n",
    "\n",
    "pcds = prepare_multiway_dataset(voxel_size=VOXEL_SIZE)\n",
    "o3d.visualization.draw_geometries(\n",
    "    pcds,\n",
    "    zoom=0.3412,\n",
    "    front=[0.4257, -0.2125, -0.8795],\n",
    "    lookat=[2.6172, 2.0475, 1.532],\n",
    "    up=[-0.0694, -0.9768, 0.2024],\n",
    "    window_name=\"before multiway registration\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c1ffa",
   "metadata": {},
   "source": [
    "Below two function defines the pairwise registration and multi-way registration function.\n",
    "\n",
    "For pairwise registration, we apply ICP twice in coarse-to-fine manner to reduce the computational cost.  \n",
    "\n",
    "In ```multiway_registration``` function, we construct the initial pose graph.  \n",
    "Each node in pose graph is the input point cloud fragments, and we initialize edges using the relative transformation information predicted with ```pairwise_registration``` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d228c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_registration(source, target, distance_coarse, distance_fine):\n",
    "    print(\"Apply point-to-plane ICP\")\n",
    "    icp_coarse = o3d.pipelines.registration.registration_icp(\n",
    "        source,\n",
    "        target,\n",
    "        distance_coarse,\n",
    "        np.identity(4),\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane(),\n",
    "    )\n",
    "    icp_fine = o3d.pipelines.registration.registration_icp(\n",
    "        source,\n",
    "        target,\n",
    "        distance_fine,\n",
    "        icp_coarse.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane(),\n",
    "    )\n",
    "    transformation_icp = icp_fine.transformation\n",
    "    information_icp = (\n",
    "        o3d.pipelines.registration.get_information_matrix_from_point_clouds(\n",
    "            source, target, distance_fine, icp_fine.transformation\n",
    "        )\n",
    "    )\n",
    "    return transformation_icp, information_icp\n",
    "\n",
    "\n",
    "def multiway_registration(pcds, distance_coarse, distance_fine):\n",
    "    pose_graph = o3d.pipelines.registration.PoseGraph()\n",
    "    odometry = np.identity(4)\n",
    "    pose_graph.nodes.append(o3d.pipelines.registration.PoseGraphNode(odometry))\n",
    "    n_pcds = len(pcds)\n",
    "    for source_id in range(n_pcds):\n",
    "        for target_id in range(source_id + 1, n_pcds):\n",
    "            transformation_icp, information_icp = pairwise_registration(\n",
    "                pcds[source_id], pcds[target_id], distance_coarse, distance_fine\n",
    "            )\n",
    "            print(\"Build o3d.pipelines.registration.PoseGraph\")\n",
    "            if target_id == source_id + 1:  # odometry case\n",
    "                odometry = np.dot(transformation_icp, odometry)\n",
    "                pose_graph.nodes.append(\n",
    "                    o3d.pipelines.registration.PoseGraphNode(np.linalg.inv(odometry))\n",
    "                )\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(\n",
    "                        source_id,\n",
    "                        target_id,\n",
    "                        transformation_icp,\n",
    "                        information_icp,\n",
    "                        uncertain=False,\n",
    "                    )\n",
    "                )\n",
    "            else:  # loop closure case\n",
    "                pose_graph.edges.append(\n",
    "                    o3d.pipelines.registration.PoseGraphEdge(\n",
    "                        source_id,\n",
    "                        target_id,\n",
    "                        transformation_icp,\n",
    "                        information_icp,\n",
    "                        uncertain=True,\n",
    "                    )\n",
    "                )\n",
    "    return pose_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db18326",
   "metadata": {},
   "source": [
    "Build initial pose graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_graph = multiway_registration(\n",
    "    pcds, max_correspondence_distance_coarse, max_correspondence_distance_fine\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba045b8",
   "metadata": {},
   "source": [
    "Then we apply global optimization algorithm on the constructed pose graph to perform multiway registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e81cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "option = o3d.pipelines.registration.GlobalOptimizationOption(\n",
    "    max_correspondence_distance=max_correspondence_distance_fine,\n",
    "    edge_prune_threshold=0.25,\n",
    "    reference_node=0,\n",
    ")\n",
    "o3d.pipelines.registration.global_optimization(\n",
    "    pose_graph,\n",
    "    o3d.pipelines.registration.GlobalOptimizationLevenbergMarquardt(),\n",
    "    o3d.pipelines.registration.GlobalOptimizationConvergenceCriteria(),\n",
    "    option,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9993ac2",
   "metadata": {},
   "source": [
    "After the pose graph is optimized, we visualize the results.\n",
    "\n",
    "As seen in the visualization, the multiway registration algorithm of Open3D succesfully register multiple point cloud fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for point_id in range(len(pcds)):\n",
    "    pcds[point_id].transform(pose_graph.nodes[point_id].pose)\n",
    "o3d.visualization.draw_geometries(\n",
    "    pcds,\n",
    "    zoom=0.3412,\n",
    "    front=[0.4257, -0.2125, -0.8795],\n",
    "    lookat=[2.6172, 2.0475, 1.532],\n",
    "    up=[-0.0694, -0.9768, 0.2024],\n",
    "    window_name=\"after multiway registration\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34c9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e2e78d7be17a1ba932626bfa8907369e94fa71a421e334df4963660b8d86e08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
