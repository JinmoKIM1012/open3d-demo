{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "672ff33f-7a57-435f-9642-4ef6521446f0",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial demonstrates a RGB-D surface reconstruction method implemented in Open3D.\n",
    "\n",
    "The reconstruction algorithm is a scalable integration algorithm that utilizes a hierarchical hash structure to integrate each RGB-D frame into Truncated Signed Distance Fields (TSDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19080a-2009-4ddf-89b4-d9e3462d93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d84f9a4-df74-452e-82f3-2256c73ffbab",
   "metadata": {},
   "source": [
    "## 1. Dataset preparation\n",
    "\n",
    "The first step in this tutorial is to download datasets and preprocess them.  \n",
    "In Open3D, there is a helper function to download various demo datasets for various tasks.  \n",
    "\n",
    "We download and read RGB-D images from a sampled Redwood dataset by using ```SampleRedwoodRGBDImage()``` function in ```open3d.data``` namespace.\n",
    "Along with the RGB-D frames, we also need the camera trajectory data for each frame. \n",
    "We use the below code to read the RGB-D frames and camera poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37250d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trajectory(filename):\n",
    "    traj = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        metastr = f.readline()\n",
    "        while metastr:\n",
    "            metadata = list(map(int, metastr.split()))\n",
    "            mat = np.zeros(shape=(4, 4))\n",
    "            for i in range(4):\n",
    "                matstr = f.readline()\n",
    "                mat[i, :] = np.fromstring(matstr, dtype=float, sep=\" \\t\")\n",
    "            traj.append(mat)\n",
    "            metastr = f.readline()\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473902dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    redwood = o3d.data.SampleRedwoodRGBDImages()\n",
    "    camera_poses = read_trajectory(redwood.odometry_log_path)\n",
    "    return redwood, camera_poses\n",
    "\n",
    "\n",
    "redwood, camera_poses = prepare_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f53339-41a2-41c4-b76b-12862fddb64b",
   "metadata": {},
   "source": [
    "## 2. Visualize data\n",
    "\n",
    "This code below visualizes all RGB-D frames in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeaad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, len(camera_poses) * 4))\n",
    "for i in range(len(camera_poses)):\n",
    "    color = o3d.io.read_image(redwood.color_paths[i])\n",
    "    depth = o3d.io.read_image(redwood.depth_paths[i])\n",
    "    ax1 = fig.add_subplot(len(camera_poses), 2, 1 + 2 * i)\n",
    "    ax1.imshow(np.asarray(color))\n",
    "    ax1.axis(\"off\")\n",
    "    ax2 = fig.add_subplot(len(camera_poses), 2, 2 + 2 * i)\n",
    "    ax2.imshow(np.asarray(depth))\n",
    "    ax2.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fffca47-1bc4-4a21-9b1e-2385d3785936",
   "metadata": {},
   "source": [
    "## 3. TSDF Volume integration\n",
    "\n",
    "Open3D provides two types of TSDF volume implementation. \n",
    "```ScalableTSDFVolume``` is one of the available implementations, and it implements a hierarchical hash structure for supporting larger scenes.\n",
    "\n",
    "We can initialize TSDF volume by using the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d932ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "    voxel_length=4.0 / 512.0,\n",
    "    sdf_trunc=0.04,\n",
    "    color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce9724-9011-41b8-acef-2bf0b82a47b1",
   "metadata": {},
   "source": [
    "## 4. TSDF volume integration\n",
    "\n",
    "Then, for each RGB-D frame, we unproject the 2D RGB-D image into 3D volume using the camera pose\n",
    "The unprojected image is then integrated it into the TSDF volume defined in the above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db0ef8-38ac-4d02-9ec7-7f710044d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(camera_poses)):\n",
    "    print(\"Integrate {:d}-th image into the volume.\".format(i))\n",
    "    color = o3d.io.read_image(redwood.color_paths[i])\n",
    "    depth = o3d.io.read_image(redwood.depth_paths[i])\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color, depth, depth_trunc=4.0, convert_rgb_to_intensity=False\n",
    "    )\n",
    "    volume.integrate(\n",
    "        rgbd,\n",
    "        o3d.camera.PinholeCameraIntrinsic(\n",
    "            o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault\n",
    "        ),\n",
    "        np.linalg.inv(camera_poses[i]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9326a03f-32a3-4cab-97e8-8964654a7900",
   "metadata": {},
   "source": [
    "## 5. Extract a mesh\n",
    "\n",
    "Finally, we can extract a mesh from TSDF volume by using marching cude algorithm. \n",
    "In Open3D, ```extract_triangle_mesh``` function of TSDF volume is provided for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ec35fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extract a triangle mesh from the volume and visualize it.\")\n",
    "mesh = volume.extract_triangle_mesh()\n",
    "mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_geometries(\n",
    "    [mesh],\n",
    "    front=[0.5297, -0.1873, -0.8272],\n",
    "    lookat=[2.0712, 2.0312, 1.7251],\n",
    "    up=[-0.0558, -0.9809, 0.1864],\n",
    "    zoom=0.47,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
