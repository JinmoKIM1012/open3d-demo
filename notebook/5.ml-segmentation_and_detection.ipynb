{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc05fec",
   "metadata": {},
   "source": [
    "# Training a semantic segmentation model using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25922b0",
   "metadata": {},
   "source": [
    "In this tutorial, we will learn how to train a semantic segmentation model using PyTorch.\n",
    "\n",
    "Before you begin, ensure that you have *PyTorch* installed. To install a compatible version of PyTorch, use the requirement file:\n",
    "\n",
    "```sh\n",
    "pip install -r requirements-torch-cuda.txt\n",
    "```\n",
    "\n",
    "At a high level, we will:\n",
    "\n",
    "- Read a dataset and create a *'training'* split. For this example, we will use the `SemanticKITTI` dataset.\n",
    "- Train a model. We will train a `RandLANet` model on the *'training'* split.\n",
    "- Run a test on a *'test'* split to evaluate the model.\n",
    "- Run an inference on a custom point cloud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e89bac",
   "metadata": {},
   "source": [
    "## Reading a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff079f",
   "metadata": {},
   "source": [
    "Downloading scripts are available in: `Open3D-ML/scripts/download_datasets`\n",
    "\n",
    "You can use any dataset available in the `ml3d.datasets` dataset namespace. Here, we will use the `SemanticKITTI` dataset and visualize it. You can use any of the other datasets to load data. However, you must understand that the parameters may vary for each dataset.\n",
    "\n",
    "We will read the dataset by specifying its path and then get all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "508129cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-10-19 03:13:43,009 - semantickitti - Found 4541 pointclouds for training\n"
     ]
    }
   ],
   "source": [
    "# Training Semantic Segmentation Model using PyTorch\n",
    "\n",
    "# import torch\n",
    "import open3d.ml.torch as ml3d\n",
    "\n",
    "# Read a dataset by specifying the path. We are also providing the cache directory and training split.\n",
    "dataset = ml3d.datasets.SemanticKITTI(dataset_path='/root/data/kitti_odometry/',\n",
    "                                      cache_dir='logs/cache',\n",
    "                                      training_split=['00'],\n",
    "                                      validation_split=['01'],\n",
    "                                      test_split=['01'])\n",
    "\n",
    "# Split the dataset for 'training'. You can get the other splits by passing 'validation' or 'test'\n",
    "train_split = dataset.get_split('training')\n",
    "\n",
    "#support of Open3d-ML visualizer in Jupyter Notebooks is in progress\n",
    "#view the frames using the visualizer\n",
    "#vis = ml3d.vis.Visualizer()\n",
    "#vis.visualize_dataset(dataset, 'training',indices=range(len(train_split)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34dca8f",
   "metadata": {},
   "source": [
    "Now that you have visualized the dataset for training, let us train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc77ea",
   "metadata": {},
   "source": [
    "## Training a model\n",
    "\n",
    "First, import the desired model from `open3d.ml.torch.models`.\n",
    "\n",
    "After you load a dataset, you can initialize any model and then train the model. The following example shows how you can train RandLANet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c1ff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-10-19 03:13:53,936 - semantic_segmentation - DEVICE : cuda\n",
      "INFO - 2022-10-19 03:13:53,938 - semantic_segmentation - Logging in file : ./logs/RandLANet_SemanticKITTI_torch/log_train_2022-10-19_03:13:53.txt\n",
      "INFO - 2022-10-19 03:13:53,951 - semantickitti - Found 4541 pointclouds for train\n",
      "INFO - 2022-10-19 03:13:53,954 - semantickitti - Found 1101 pointclouds for validation\n",
      "INFO - 2022-10-19 03:13:53,955 - semantic_segmentation - Initializing from scratch.\n",
      "INFO - 2022-10-19 03:13:53,958 - semantic_segmentation - Writing summary in train_log/00001_RandLANet_SemanticKITTI_torch.\n",
      "INFO - 2022-10-19 03:13:53,958 - semantic_segmentation - Started training\n",
      "INFO - 2022-10-19 03:13:53,959 - semantic_segmentation - === EPOCH 0/3 ===\n",
      "training:  11%|█         | 121/1136 [04:48<40:16,  2.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 25\u001b[0m\n\u001b[1;32m     18\u001b[0m pipeline \u001b[39m=\u001b[39m SemanticSegmentation(model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     19\u001b[0m                                 dataset\u001b[39m=\u001b[39mdataset,\n\u001b[1;32m     20\u001b[0m                                 max_epoch\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m     21\u001b[0m                                 optimizer\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.001\u001b[39m},\n\u001b[1;32m     22\u001b[0m                                 num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39m# Run the training\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m pipeline\u001b[39m.\u001b[39;49mrun_train()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/open3d/_ml3d/torch/pipelines/semantic_segmentation.py:421\u001b[0m, in \u001b[0;36mSemanticSegmentation.run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mgrad_clip_norm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    419\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_value_(model\u001b[39m.\u001b[39mparameters(),\n\u001b[1;32m    420\u001b[0m                                     model\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mgrad_clip_norm)\n\u001b[0;32m--> 421\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    423\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric_train\u001b[39m.\u001b[39mupdate(predict_scores, gt_labels)\n\u001b[1;32m    425\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/torch/optim/adam.py:108\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    107\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 108\u001b[0m     F\u001b[39m.\u001b[39;49madam(params_with_grad,\n\u001b[1;32m    109\u001b[0m            grads,\n\u001b[1;32m    110\u001b[0m            exp_avgs,\n\u001b[1;32m    111\u001b[0m            exp_avg_sqs,\n\u001b[1;32m    112\u001b[0m            max_exp_avg_sqs,\n\u001b[1;32m    113\u001b[0m            state_steps,\n\u001b[1;32m    114\u001b[0m            group[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    115\u001b[0m            beta1,\n\u001b[1;32m    116\u001b[0m            beta2,\n\u001b[1;32m    117\u001b[0m            group[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    118\u001b[0m            group[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    119\u001b[0m            group[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    120\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/torch/optim/_functional.py:85\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m     84\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[0;32m---> 85\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39;49maddcmul_(grad, grad, value\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta2)\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m amsgrad:\n\u001b[1;32m     87\u001b[0m     \u001b[39m# Maintains the maximum of all 2nd moment running avg. till now\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     torch\u001b[39m.\u001b[39mmaximum(max_exp_avg_sqs[i], exp_avg_sq, out\u001b[39m=\u001b[39mmax_exp_avg_sqs[i])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training Semantic Segmentation Model using PyTorch\n",
    "\n",
    "# Import torch and the model to use for training\n",
    "import open3d.ml.torch as ml3d\n",
    "from open3d.ml.torch.models import RandLANet\n",
    "from open3d.ml.torch.pipelines import SemanticSegmentation\n",
    "\n",
    "# Read a dataset by specifying the path. We are also providing the cache directory and training split.\n",
    "# dataset = ml3d.datasets.SemanticKITTI(dataset_path='/Users/sanskara/data/SemanticKITTI/', cache_dir='./logs/cache',training_split=['00'], validation_split=['01'], test_split=['01'])\n",
    "dataset = ml3d.datasets.SemanticKITTI(dataset_path='/root/data/kitti_odometry/',\n",
    "                                      cache_dir='logs/cache',\n",
    "                                      training_split=['00'],\n",
    "                                      validation_split=['01'],\n",
    "                                      test_split=['01'])\n",
    "\n",
    "# Initialize the RandLANet model.\n",
    "model = RandLANet(in_channels=3)\n",
    "pipeline = SemanticSegmentation(model=model,\n",
    "                                dataset=dataset,\n",
    "                                max_epoch=3,\n",
    "                                optimizer={'lr': 0.001},\n",
    "                                num_workers=0)\n",
    "\n",
    "# Run the training\n",
    "pipeline.run_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0b0bc9",
   "metadata": {},
   "source": [
    "The training checkpoints are saved in: `pipeline.main_log_dir` (default path is: “./logs/Model_Dataset/“). You can use them for testing and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4fa94c",
   "metadata": {},
   "source": [
    "## Running a test\n",
    "\n",
    "Next, we will evaluate the trained model on the test split by calling the `run_test()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f461dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-10-19 03:18:46,988 - semantic_segmentation - DEVICE : cuda\n",
      "INFO - 2022-10-19 03:18:46,989 - semantic_segmentation - Logging in file : ./logs/RandLANet_SemanticKITTI_torch/log_test_2022-10-19_03:18:46.txt\n",
      "INFO - 2022-10-19 03:18:46,993 - semantickitti - Found 1101 pointclouds for test\n",
      "INFO - 2022-10-19 03:22:54,504 - semantic_segmentation - Initializing from scratch.\n",
      "INFO - 2022-10-19 03:22:54,506 - semantic_segmentation - Started testing\n",
      "test 0/1101: 100%|██████████| 90404/90404 [00:05<00:00, 14871.08it/s]INFO - 2022-10-19 03:23:01,693 - semantic_segmentation - Accuracy : [0.00303951367781155, nan, nan, nan, nan, nan, nan, nan, 0.5496127929196419, nan, nan, nan, nan, 0.0, 0.00728126834997064, nan, 0.00018758206715438003, 0.0, 0.0, 0.08001730814493979]\n",
      "INFO - 2022-10-19 03:23:01,694 - semantic_segmentation - IoU : [6.836204539239814e-05, nan, nan, nan, nan, nan, nan, nan, 0.3575316654454098, nan, 0.0, nan, 0.0, 0.0, 0.00728126834997064, nan, 0.00018508664368507507, 0.0, 0.0, 0.040562931387161986]\n",
      "test 0/1101: 100%|██████████| 90404/90404 [00:07<00:00, 12630.88it/s]\n",
      "INFO - 2022-10-19 03:23:08,425 - semantic_segmentation - Accuracy : [0.001455604075691412, nan, nan, nan, nan, nan, nan, nan, 0.5636300559160851, nan, nan, nan, nan, 0.0, 0.005549257115579688, nan, 9.167268268646797e-05, 0.0, 0.0, 0.08153236997000611]\n",
      "INFO - 2022-10-19 03:23:08,426 - semantic_segmentation - IoU : [3.391555027980329e-05, nan, nan, nan, nan, nan, nan, nan, 0.3653282716384151, nan, 0.0, nan, 0.0, 0.0, 0.005549257115579688, nan, 9.052128947576859e-05, 0.0, 0.0, 0.04122244062152782]\n",
      "test 1/1101: 100%|██████████| 90318/90318 [00:06<00:00, 13447.20it/s]\n",
      "test 2/1101:  97%|█████████▋| 88182/90449 [00:03<00:00, 22838.01it/s]INFO - 2022-10-19 03:23:15,427 - semantic_segmentation - Accuracy : [0.0009505703422053232, nan, nan, nan, nan, nan, nan, nan, 0.5622674334315952, nan, nan, nan, nan, 0.0, 0.004138465302128354, nan, 5.957123602868355e-05, 0.0, 0.0, 0.08105943433027966]\n",
      "INFO - 2022-10-19 03:23:15,429 - semantic_segmentation - IoU : [2.2847220635609676e-05, nan, nan, nan, nan, nan, nan, nan, 0.3627775006235969, nan, 0.0, nan, 0.0, 0.0, 0.004138465302128354, nan, 5.89066918001885e-05, 0.0, 0.0, 0.04077752442646235]\n",
      "test 2/1101: 100%|██████████| 90449/90449 [00:07<00:00, 12455.72it/s]\n",
      "INFO - 2022-10-19 03:23:24,452 - semantic_segmentation - Accuracy : [0.0007027406886858749, nan, nan, nan, nan, nan, nan, nan, 0.5762947076263167, nan, nan, nan, nan, 0.0, 0.003375960670836056, nan, 4.364668012439304e-05, 0.0, 0.0, 0.08291672223799472]\n",
      "INFO - 2022-10-19 03:23:24,458 - semantic_segmentation - IoU : [1.6858005023685498e-05, nan, nan, nan, nan, nan, nan, nan, 0.3705323495912153, nan, 0.0, nan, 0.0, 0.0, 0.003375960670836056, nan, 4.322735426978192e-05, 0.0, 0.0, 0.0415520439579272]\n",
      "test 3/1101: 100%|██████████| 90828/90828 [00:09<00:00, 9689.14it/s] \n",
      "test 4/1101: 100%|██████████| 90559/90559 [00:05<00:00, 12481.47it/s]INFO - 2022-10-19 03:23:32,637 - semantic_segmentation - Accuracy : [0.0005605381165919282, nan, nan, nan, nan, nan, nan, nan, 0.5830945925205914, nan, nan, nan, nan, 0.0, 0.0027467659046606415, nan, 3.419402544890344e-05, 0.0, 0.0, 0.08377658436675613]\n",
      "INFO - 2022-10-19 03:23:32,640 - semantic_segmentation - IoU : [1.3264534613803075e-05, nan, nan, nan, nan, nan, nan, nan, 0.3734202270996066, nan, 0.0, nan, 0.0, 0.0, 0.0027467659046606415, nan, 3.390735662486172e-05, 0.0, 0.0, 0.04180157387727843]\n",
      "test 4/1101: 100%|██████████| 90559/90559 [00:07<00:00, 11579.87it/s]\n",
      "INFO - 2022-10-19 03:23:40,531 - semantic_segmentation - Accuracy : [0.0009601536245799327, nan, nan, nan, nan, nan, nan, nan, 0.5921840586177609, nan, nan, nan, nan, 0.0, 0.002323340471092077, nan, 2.7935887139015958e-05, 0.0, 0.0, 0.08507078408579598]\n",
      "INFO - 2022-10-19 03:23:40,532 - semantic_segmentation - IoU : [2.1715055047664545e-05, nan, nan, nan, nan, nan, nan, nan, 0.3792806186541276, nan, 0.0, nan, 0.0, 0.0, 0.002323340471092077, nan, 2.7725984099148118e-05, 0.0, 0.0, 0.04240593335159628]\n",
      "test 5/1101: 100%|██████████| 90784/90784 [00:07<00:00, 11494.19it/s]\n",
      "test 6/1101: 100%|█████████▉| 90473/90512 [00:05<00:00, 11900.31it/s]INFO - 2022-10-19 03:23:50,340 - semantic_segmentation - Accuracy : [0.026767043078209953, nan, nan, nan, nan, nan, nan, nan, 0.6013861948981281, nan, nan, nan, nan, 0.0, 0.0020153426082434012, nan, 2.3531557289046943e-05, 0.0, 0.0, 0.09002744459169579]\n",
      "INFO - 2022-10-19 03:23:50,341 - semantic_segmentation - IoU : [0.0005869136594983723, nan, nan, nan, nan, nan, nan, nan, 0.38494588828975806, nan, 0.0, nan, 0.0, 0.0, 0.0020153426082434012, nan, 2.337158482716713e-05, 0.0, 0.0, 0.04306350179359189]\n",
      "test 6/1101: 100%|██████████| 90512/90512 [00:09<00:00, 9053.21it/s] \n",
      "INFO - 2022-10-19 03:23:58,782 - semantic_segmentation - Accuracy : [0.043592634347989476, nan, nan, nan, nan, nan, nan, nan, 0.6094446825276139, nan, nan, nan, nan, 0.0, 0.0017845247983158032, nan, 2.0261936179966517e-05, 0.0, 0.0, 0.09354887194429987]\n",
      "INFO - 2022-10-19 03:23:58,783 - semantic_segmentation - IoU : [0.0009199777936394639, nan, nan, nan, nan, nan, nan, nan, 0.38963699613238967, nan, 0.0, nan, 0.0, 0.0, 0.0017845247983158032, nan, 2.013145842350549e-05, 0.0, 0.0, 0.04359573668697427]\n",
      "test 7/1101: 100%|██████████| 90574/90574 [00:08<00:00, 10508.02it/s]\n",
      "test 8/1101: 100%|██████████| 90401/90401 [00:06<00:00, 11002.81it/s]INFO - 2022-10-19 03:24:08,133 - semantic_segmentation - Accuracy : [0.04, nan, nan, nan, nan, nan, nan, nan, 0.6162677786028445, nan, nan, nan, nan, 0.0, 0.001619762582744721, nan, 1.7770432665609325e-05, 0.0, 0.0, 0.09398647308832213]\n",
      "INFO - 2022-10-19 03:24:08,135 - semantic_segmentation - IoU : [0.0008102991820169464, nan, nan, nan, nan, nan, nan, nan, 0.3936123470302252, nan, 0.0, nan, 0.0, 0.0, 0.0016196308129215477, nan, 1.765957634676344e-05, 0.0, 0.0, 0.04400665962239005]\n",
      "test 8/1101: 100%|██████████| 90401/90401 [00:09<00:00, 9809.33it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipeline\u001b[39m.\u001b[39;49mrun_test()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/open3d/_ml3d/torch/pipelines/semantic_segmentation.py:230\u001b[0m, in \u001b[0;36mSemanticSegmentation.run_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mStarted testing\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    229\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mfor\u001b[39;00m unused_step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_loader):\n\u001b[1;32m    231\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(inputs[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mto\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    232\u001b[0m             inputs[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/torch/utils/data/dataloader.py:517\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 517\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    518\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    520\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    521\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    556\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    559\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 44\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     45\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/open3d/_ml3d/torch/dataloaders/torch_dataloader.py:81\u001b[0m, in \u001b[0;36mTorchDataloader.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     79\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_convert(attr[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     80\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess:\n\u001b[0;32m---> 81\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocess(dataset\u001b[39m.\u001b[39;49mget_data(index), attr)\n\u001b[1;32m     82\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     data \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mget_data(index)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/open3d/_ml3d/torch/models/randlanet.py:150\u001b[0m, in \u001b[0;36mRandLANet.preprocess\u001b[0;34m(self, data, attr)\u001b[0m\n\u001b[1;32m    146\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39msearch_tree\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m search_tree\n\u001b[1;32m    148\u001b[0m \u001b[39mif\u001b[39;00m split \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    149\u001b[0m     proj_inds \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(\n\u001b[0;32m--> 150\u001b[0m         search_tree\u001b[39m.\u001b[39;49mquery(points, return_distance\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m))\n\u001b[1;32m    151\u001b[0m     proj_inds \u001b[39m=\u001b[39m proj_inds\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint32)\n\u001b[1;32m    152\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mproj_inds\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m proj_inds\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline.run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a385892",
   "metadata": {},
   "source": [
    "## Running a pre-trained RandLANet (3D Semantic Segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d39c5381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-10-19 03:34:15,721 - semantic_segmentation - Loading checkpoint pretrained_weights/randlanet_semantickitti_202201071330utc.pth\n",
      "INFO - 2022-10-19 03:34:15,827 - semantickitti - Found 20351 pointclouds for test\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/open3d/_ml3d/torch/modules/metrics/semseg_metric.py:54: RuntimeWarning: Mean of empty slice\n",
      "  accs.append(np.nanmean(accs))\n",
      "INFO - 2022-10-19 03:34:25,495 - semantic_segmentation - Accuracy : [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/open3d/_ml3d/torch/modules/metrics/semseg_metric.py:87: RuntimeWarning: Mean of empty slice\n",
      "  ious.append(np.nanmean(ious))\n",
      "INFO - 2022-10-19 03:34:25,500 - semantic_segmentation - IoU : [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "INFO - 2022-10-19 03:34:25,504 - semantic_segmentation - DEVICE : cuda\n",
      "INFO - 2022-10-19 03:34:25,505 - semantic_segmentation - Logging in file : ./logs/RandLANet_SemanticKITTI_torch/log_test_2022-10-19_03:34:25.txt\n",
      "INFO - 2022-10-19 03:34:25,552 - semantickitti - Found 20351 pointclouds for test\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "preprocess:   3%|▎         | 593/20351 [02:16<1:15:42,  4.35it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m result \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mrun_inference(data)\n\u001b[1;32m     32\u001b[0m \u001b[39m# evaluate performance on the test set; this will write logs to './logs'.\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m pipeline\u001b[39m.\u001b[39;49mrun_test()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/open3d/_ml3d/torch/pipelines/semantic_segmentation.py:205\u001b[0m, in \u001b[0;36mSemanticSegmentation.run_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m test_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mget_split(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    204\u001b[0m test_sampler \u001b[39m=\u001b[39m test_dataset\u001b[39m.\u001b[39msampler\n\u001b[0;32m--> 205\u001b[0m test_split \u001b[39m=\u001b[39m TorchDataloader(dataset\u001b[39m=\u001b[39;49mtest_dataset,\n\u001b[1;32m    206\u001b[0m                              preprocess\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpreprocess,\n\u001b[1;32m    207\u001b[0m                              transform\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtransform,\n\u001b[1;32m    208\u001b[0m                              sampler\u001b[39m=\u001b[39;49mtest_sampler,\n\u001b[1;32m    209\u001b[0m                              use_cache\u001b[39m=\u001b[39;49mdataset\u001b[39m.\u001b[39;49mcfg\u001b[39m.\u001b[39;49muse_cache)\n\u001b[1;32m    210\u001b[0m test_loader \u001b[39m=\u001b[39m DataLoader(test_split,\n\u001b[1;32m    211\u001b[0m                          batch_size\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mtest_batch_size,\n\u001b[1;32m    212\u001b[0m                          sampler\u001b[39m=\u001b[39mget_sampler(test_sampler),\n\u001b[1;32m    213\u001b[0m                          collate_fn\u001b[39m=\u001b[39mbatcher\u001b[39m.\u001b[39mcollate_fn)\n\u001b[1;32m    215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_split \u001b[39m=\u001b[39m test_dataset\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/open3d/_ml3d/torch/dataloaders/torch_dataloader.py:62\u001b[0m, in \u001b[0;36mTorchDataloader.__init__\u001b[0;34m(self, dataset, preprocess, transform, sampler, use_cache, steps_per_epoch, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             data \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mget_data(idx)\n\u001b[1;32m     61\u001b[0m             \u001b[39m# cache the data\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_convert(name, data, attr)\n\u001b[1;32m     64\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_convert \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/open3d/_ml3d/utils/dataset_helper.py:56\u001b[0m, in \u001b[0;36mCache.__call__\u001b[0;34m(self, unique_id, *data)\u001b[0m\n\u001b[1;32m     53\u001b[0m fpath \u001b[39m=\u001b[39m join(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache_dir, \u001b[39mstr\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(unique_id)))\n\u001b[1;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exists(fpath):\n\u001b[0;32m---> 56\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49mdata)\n\u001b[1;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write(output, fpath)\n\u001b[1;32m     59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached_ids\u001b[39m.\u001b[39mappend(unique_id)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/open3d/_ml3d/torch/models/randlanet.py:141\u001b[0m, in \u001b[0;36mRandLANet.preprocess\u001b[0;34m(self, data, attr)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     sub_points, sub_feat, sub_labels \u001b[39m=\u001b[39m DataProcessing\u001b[39m.\u001b[39mgrid_subsampling(\n\u001b[1;32m    139\u001b[0m         points, features\u001b[39m=\u001b[39mfeat, labels\u001b[39m=\u001b[39mlabels, grid_size\u001b[39m=\u001b[39mcfg\u001b[39m.\u001b[39mgrid_size)\n\u001b[0;32m--> 141\u001b[0m search_tree \u001b[39m=\u001b[39m KDTree(sub_points)\n\u001b[1;32m    143\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mpoint\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sub_points\n\u001b[1;32m    144\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mfeat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sub_feat\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import open3d.ml as _ml3d\n",
    "import open3d.ml.torch as ml3d\n",
    "\n",
    "\n",
    "cfg_file = \"configs/randlanet_semantickitti.yml\"\n",
    "cfg = _ml3d.utils.Config.load_from_file(cfg_file)\n",
    "\n",
    "model = ml3d.models.RandLANet(**cfg.model)\n",
    "cfg.dataset['dataset_path'] = \"/root/data/kitti_odometry/\"\n",
    "dataset = ml3d.datasets.SemanticKITTI(cfg.dataset.pop('dataset_path', None), **cfg.dataset)\n",
    "pipeline = ml3d.pipelines.SemanticSegmentation(model, dataset=dataset, device=\"gpu\", **cfg.pipeline)\n",
    "\n",
    "# download the weights.\n",
    "ckpt_folder = \"pretrained_weights\"\n",
    "os.makedirs(ckpt_folder, exist_ok=True)\n",
    "ckpt_path = ckpt_folder + \"/randlanet_semantickitti_202201071330utc.pth\"\n",
    "randlanet_url = \"https://storage.googleapis.com/open3d-releases/model-zoo/randlanet_semantickitti_202201071330utc.pth\"\n",
    "if not os.path.exists(ckpt_path):\n",
    "    cmd = \"wget {} -O {}\".format(randlanet_url, ckpt_path)\n",
    "    os.system(cmd)\n",
    "\n",
    "# load the parameters.\n",
    "pipeline.load_ckpt(ckpt_path=ckpt_path)\n",
    "\n",
    "test_split = dataset.get_split(\"test\")\n",
    "data = test_split.get_data(0)\n",
    "\n",
    "# run inference on a single example.\n",
    "# returns dict with 'predict_labels' and 'predict_scores'.\n",
    "result = pipeline.run_inference(data)\n",
    "\n",
    "# evaluate performance on the test set; this will write logs to './logs'.\n",
    "pipeline.run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a385892",
   "metadata": {},
   "source": [
    "## Running a pre-trained PointPillars (3D Object Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e457cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-10-19 03:46:08,577 - object_detection - Loading checkpoint pretrained_weights/pointpillars_kitti_202012221652utc.pth\n",
      "INFO - 2022-10-19 03:46:08,616 - kitti - Found 0 pointclouds for test\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m pipeline\u001b[39m.\u001b[39mload_ckpt(ckpt_path\u001b[39m=\u001b[39mckpt_path)\n\u001b[1;32m     26\u001b[0m test_split \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mget_split(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m data \u001b[39m=\u001b[39m test_split\u001b[39m.\u001b[39;49mget_data(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     29\u001b[0m \u001b[39m# run inference on a single example.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# returns dict with 'predict_labels' and 'predict_scores'.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m result \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39mrun_inference(data)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/o3d/lib/python3.8/site-packages/open3d/_ml3d/datasets/kitti.py:268\u001b[0m, in \u001b[0;36mKITTISplit.get_data\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_data\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m--> 268\u001b[0m     pc_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath_list[idx]\n\u001b[1;32m    269\u001b[0m     label_path \u001b[39m=\u001b[39m pc_path\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mvelodyne\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    270\u001b[0m                                  \u001b[39m'\u001b[39m\u001b[39mlabel_2\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.bin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    271\u001b[0m     calib_path \u001b[39m=\u001b[39m label_path\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mlabel_2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcalib\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import open3d.ml as _ml3d\n",
    "import open3d.ml.torch as ml3d\n",
    "\n",
    "\n",
    "cfg_file = \"configs/pointpillars_kitti.yml\"\n",
    "cfg = _ml3d.utils.Config.load_from_file(cfg_file)\n",
    "\n",
    "model = ml3d.models.PointPillars(**cfg.model)\n",
    "cfg.dataset['dataset_path'] = \"/root/data/kitti_odometry/\"\n",
    "dataset = ml3d.datasets.KITTI(cfg.dataset.pop('dataset_path', None), **cfg.dataset)\n",
    "pipeline = ml3d.pipelines.ObjectDetection(model, dataset=dataset, device=\"gpu\", **cfg.pipeline)\n",
    "\n",
    "# download the weights.\n",
    "ckpt_folder = \"pretrained_weights\"\n",
    "os.makedirs(ckpt_folder, exist_ok=True)\n",
    "ckpt_path = ckpt_folder + \"/pointpillars_kitti_202012221652utc.pth\"\n",
    "pointpillar_url = \"https://storage.googleapis.com/open3d-releases/model-zoo/pointpillars_kitti_202012221652utc.pth\"\n",
    "if not os.path.exists(ckpt_path):\n",
    "    cmd = \"wget {} -O {}\".format(pointpillar_url, ckpt_path)\n",
    "    os.system(cmd)\n",
    "\n",
    "# load the parameters.\n",
    "pipeline.load_ckpt(ckpt_path=ckpt_path)\n",
    "\n",
    "test_split = dataset.get_split(\"test\")\n",
    "data = test_split.get_data(0)\n",
    "\n",
    "# run inference on a single example.\n",
    "# returns dict with 'predict_labels' and 'predict_scores'.\n",
    "result = pipeline.run_inference(data)\n",
    "\n",
    "# evaluate performance on the test set; this will write logs to './logs'.\n",
    "pipeline.run_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('o3d')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ad67def7584ea39292f826b6da089dc591c907ef13d51cf16952b0dffd7c592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
